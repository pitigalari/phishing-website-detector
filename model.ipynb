{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdGWvDZfdLCASqw1LHyL5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshsoftco/phishing-website-detector/blob/1.0/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfIgBUr8TgzB"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLAIs9pWSarg"
      },
      "source": [
        "Dataset contains 30 attributes. Each row has 31 values, 30 attributes and the class.\n",
        "\n",
        "The `labelSplitter` function will split the last value from each row, and return them as an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU-f4tmmQnUG"
      },
      "source": [
        "import time\n",
        "\n",
        "def labelSplitter(csv):\n",
        "  \"\"\"\n",
        "  Splits the last value from each row of the parsed csv dataset as class.\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  csv : read_csv value from pandas\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  array\n",
        "    containing the data[] and the labels[]\n",
        "  \"\"\"\n",
        "\n",
        "  data = []\n",
        "  labels = []\n",
        "  for rowArray in csv.values: # iterate through dataset row by row\n",
        "    row = rowArray.tolist()\n",
        "    labels.append(row[-1]) # extract last value as class [a1, a2, ..., class]\n",
        "    \n",
        "    if rm is not None:\n",
        "      for ele in sorted(rm, reverse = True):  \n",
        "        del row[ele] # remove element from row\n",
        "    \n",
        "    data.append(row[:-1]); # rest of the data as attributes\n",
        "  \n",
        "  return [data, labels];\n",
        "\n",
        "def timeDiff(start, end):\n",
        "  return \"{t:.3f} ms\".format(t = (end-start))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE86sldFUB67"
      },
      "source": [
        "Read CSV files and assign to variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKRTABJ1e3Tj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "training_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/1.0/Dataset/training_dataset.csv\"\n",
        "validation_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/1.0/Dataset/validation_dataset.csv\"\n",
        "test_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/1.0/Dataset/test_dateset.csv\"\n",
        "\n",
        "# rm = [3,5,6,9,12,13,15,18,20,21,23,25,26,27,28,29] # attributes to remove (experiment)\n",
        "rm = None\n",
        "\n",
        "attributes = [\"having_IP_Address\",\n",
        "              \"URL_Length\",\n",
        "              \"Shortining_Service\",\n",
        "              \"having_At_Symbol\",\n",
        "              \"double_slash_redirecting\",\n",
        "              \"Prefix_Suffix\",\n",
        "              \"having_Sub_Domain\",\n",
        "              \"SSLfinal_State\",\n",
        "              \"Domain_registeration_length\",\n",
        "              \"Favicon\",\n",
        "              \"port\",\n",
        "              \"HTTPS_token\",\n",
        "              \"Request_URL\",\n",
        "              \"URL_of_Anchor\",\n",
        "              \"Links_in_tags\",\n",
        "              \"SFH\",\n",
        "              \"Submitting_to_email\",\n",
        "              \"Abnormal_URL\",\n",
        "              \"Redirect\",\n",
        "              \"on_mouseover\",\n",
        "              \"RightClick\",\n",
        "              \"popUpWidnow\",\n",
        "              \"Iframe\",\n",
        "              \"age_of_domain\",\n",
        "              \"DNSRecord\",\n",
        "              \"web_traffic\",\n",
        "              \"Page_Rank\",\n",
        "              \"Google_Index\",\n",
        "              \"Links_pointing_to_page\",\n",
        "              \"Statistical_report\"]\n",
        "\n",
        "if rm is not None:\n",
        "  for ele in sorted(rm, reverse = True):  \n",
        "    del attributes[ele] # remove element from row\n",
        "\n",
        "labels = [\"Legitamate\", \"Phishing\"]\n",
        "\n",
        "## Training Data\n",
        "splitted = labelSplitter(pd.read_csv(training_dataset_url, header=None))\n",
        "training_data = splitted[0]\n",
        "training_data_labels = splitted[1]\n",
        "\n",
        "## Validation Data\n",
        "splitted = labelSplitter(pd.read_csv(validation_dataset_url, header=None))\n",
        "validation_data = splitted[0]\n",
        "validation_data_labels = splitted[1]\n",
        "\n",
        "## Test Data\n",
        "splitted = labelSplitter(pd.read_csv(test_dataset_url, header=None))\n",
        "test_data = splitted[0]\n",
        "test_data_labels = splitted[1]\n",
        "\n",
        "splitted = None\n",
        "total = len(training_data_labels) + len(validation_data_labels) + len(test_data_labels)\n",
        "\n",
        "print(\"Training dataset size: \", len(training_data_labels), \"(75%)\")\n",
        "print(\"Validation dataset size: \", len(validation_data_labels), \"(20%)\")\n",
        "print(\"Testing dataset size: \", len(test_data_labels), \"(5%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SakDpMXEVQmu"
      },
      "source": [
        "# Training (Decision Tree)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBvzYiYqQZs"
      },
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "start = time.time()*1000\n",
        "clf = clf.fit(training_data, training_data_labels) # train\n",
        "end = time.time()*1000\n",
        "\n",
        "print(\"Training completed in\", timeDiff(start, end))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAnOsD-c7Ng"
      },
      "source": [
        "# import graphviz\n",
        "# dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "#                                 feature_names=attributes,\n",
        "#                                 class_names=labels,\n",
        "#                                 filled=True, rounded=True, special_characters=True)\n",
        "# graph = graphviz.Source(dot_data)\n",
        "# graph\n",
        "\n",
        "# # dot -Tpng tree.dot -o tree.png # run in terminal"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_v0q5JsCkc"
      },
      "source": [
        "# Validating Predictions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl4KmKnfsMkw"
      },
      "source": [
        "print(\"Accuracy: \")\n",
        "clf.score(validation_data, validation_data_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow2yFBylwUMt"
      },
      "source": [
        "# Testing Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaZVIcHRA3Z6"
      },
      "source": [
        "Check the accuracy of the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnVFbWjC-Z1u"
      },
      "source": [
        "# print(\"Accuracy: \")\n",
        "# clf.score(test_data, test_data_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-YnZUe7BFDG"
      },
      "source": [
        "Predict in real time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEGW-jYJwrfi"
      },
      "source": [
        "while(True):\n",
        "  print()\n",
        "  print(\"There are\", len(test_data_labels), \"instances which can be tested.\")\n",
        "  print()\n",
        "\n",
        "  row = int(input(\"Enter row index (-1 exit): \"))\n",
        "\n",
        "  if(row < 0):\n",
        "    break\n",
        "  elif(row >= len(test_data_labels)):\n",
        "    print(\"Error: Enter a number between 0 and\", (len(test_data_labels)-1))\n",
        "    continue\n",
        "\n",
        "  i = []\n",
        "  i.append(test_data[row])\n",
        "\n",
        "  start = time.time()*1000\n",
        "  prediction = clf.predict(i)[0]\n",
        "  end = time.time()*1000\n",
        "\n",
        "  testLbl = labels[0] if (test_data_labels[row] == -1) else labels[1]\n",
        "  predLbl = labels[0] if (prediction == -1) else labels[1]\n",
        "\n",
        "  print()\n",
        "  print(\"Predicted answer:\", prediction, predLbl)\n",
        "  print(\"Correct answer:\", test_data_labels[row], testLbl)\n",
        "  print()\n",
        "\n",
        "  state = \"Incorrect!\"\n",
        "  if (prediction == test_data_labels[row]):\n",
        "    state = \"Correct!\"\n",
        "  print(\"Prediction is\", state, \"(\", timeDiff(start, end) , \")\")\n",
        "  print(\"***\")\n",
        "  print()\n",
        "\n",
        "print()\n",
        "print(\"Application terminated.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}