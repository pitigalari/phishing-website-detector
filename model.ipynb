{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPznMLyyIz8Scv/VKGQDzBs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshsoftco/phishing-website-detector/blob/0.2/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfIgBUr8TgzB"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLAIs9pWSarg"
      },
      "source": [
        "Dataset contains 30 attributes. Each row has 31 values, 30 attributes and the class.\n",
        "\n",
        "The `labelSplitter` function will split the last value from each row, and return them as an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU-f4tmmQnUG"
      },
      "source": [
        "def labelSplitter(csv):\n",
        "  \"\"\"\n",
        "  Splits the last value from each row of the parsed csv dataset as class.\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  csv : read_csv value from pandas\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  array\n",
        "    containing the data[] and the labels[]\n",
        "  \"\"\"\n",
        "\n",
        "  # rm = [1, 6, 7, 13, 14, 15, 25, 28] # attributes to remove\n",
        "    \n",
        "  data = []\n",
        "  labels = []\n",
        "  for rowArray in csv.values: # iterate through dataset row by row\n",
        "    row = rowArray.tolist()\n",
        "    labels.append(row[-1]) # extract last value as class [a1, a2, ..., class]\n",
        "\n",
        "    # for ele in sorted(rm, reverse = True):  \n",
        "    #   del row[ele] # remove element from row\n",
        "    # data.append(filtered_row[:-1]);\n",
        "    \n",
        "    data.append(row[:-1]); # rest of the data as attributes\n",
        "  \n",
        "  return [data, labels];"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE86sldFUB67"
      },
      "source": [
        "Read CSV files and assign to variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKRTABJ1e3Tj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "training_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/0.2/Dataset/training_dataset.csv?token=AFSK45UKKVPMD5X5QRAUAR3AILN54\"\n",
        "validation_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/0.2/Dataset/validation_dataset.csv?token=AFSK45VZNMAQO4SVPQFPFELAILN3I\"\n",
        "test_dataset_url = \"https://raw.githubusercontent.com/roshsoftco/phishing-website-detector/0.2/Dataset/test_dateset.csv?token=AFSK45USBWRLYLNNBBCJQMDAILN7U\"\n",
        "\n",
        "labels = [\"Legitamate\", \"Phishing\"]\n",
        "\n",
        "## Training Data\n",
        "splitted = labelSplitter(pd.read_csv(training_dataset_url, header=None))\n",
        "training_data = splitted[0]\n",
        "training_data_labels = splitted[1]\n",
        "\n",
        "## Validation Data\n",
        "splitted = labelSplitter(pd.read_csv(validation_dataset_url, header=None))\n",
        "validation_data = splitted[0]\n",
        "validation_data_labels = splitted[1]\n",
        "\n",
        "## Test Data\n",
        "splitted = labelSplitter(pd.read_csv(test_dataset_url, header=None))\n",
        "test_data = splitted[0]\n",
        "test_data_labels = splitted[1]\n",
        "\n",
        "splitted = None\n",
        "\n",
        "print(\"Training dataset size: \", len(training_data_labels))\n",
        "print(\"Validation dataset size: \", len(validation_data_labels))\n",
        "print(\"Testing dataset size: \", len(test_data_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SakDpMXEVQmu"
      },
      "source": [
        "# Classifier Training (Decision Tree)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBvzYiYqQZs"
      },
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(training_data, training_data_labels) # train"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAnOsD-c7Ng"
      },
      "source": [
        "# attributes = [\"having_IP_Address\",\n",
        "#               \"URL_Length\",\n",
        "#               \"Shortining_Service\",\n",
        "#               \"having_At_Symbol\",\n",
        "#               \"double_slash_redirecting\",\n",
        "#               \"Prefix_Suffix\",\n",
        "#               \"having_Sub_Domain\",\n",
        "#               \"SSLfinal_State\",\n",
        "#               \"Domain_registeration_length\",\n",
        "#               \"Favicon\",\n",
        "#               \"port\",\n",
        "#               \"HTTPS_token\",\n",
        "#               \"Request_URL\",\n",
        "#               \"URL_of_Anchor\",\n",
        "#               \"Links_in_tags\",\n",
        "#               \"SFH\",\n",
        "#               \"Submitting_to_email\",\n",
        "#               \"Abnormal_URL\",\n",
        "#               \"Redirect\",\n",
        "#               \"on_mouseover\",\n",
        "#               \"RightClick\",\n",
        "#               \"popUpWidnow\",\n",
        "#               \"Iframe\",\n",
        "#               \"age_of_domain\",\n",
        "#               \"DNSRecord\",\n",
        "#               \"web_traffic\",\n",
        "#               \"Page_Rank\",\n",
        "#               \"Google_Index\",\n",
        "#               \"Links_pointing_to_page\",\n",
        "#               \"Statistical_report\"]\n",
        "\n",
        "# import graphviz\n",
        "# dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "#                                 feature_names=attributes,\n",
        "#                                 class_names=labels,\n",
        "#                                 filled=True, rounded=True, special_characters=True)\n",
        "# graph = graphviz.Source(dot_data)\n",
        "# graph"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_v0q5JsCkc"
      },
      "source": [
        "# Validating Predictions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl4KmKnfsMkw"
      },
      "source": [
        "predictions = clf.predict(validation_data)\n",
        "\n",
        "correct = 0\n",
        "correct_percentage = 0\n",
        "incorrect = 0\n",
        "incorrect_percentage = 0\n",
        "\n",
        "for x in range(len(predictions)):\n",
        "  if(predictions[x] == validation_data_labels[x]):\n",
        "    correct += 1\n",
        "  else:\n",
        "    incorrect += 1\n",
        "\n",
        "correct_percentage = (float(correct)/len(validation_data_labels))*100\n",
        "incorrect_percentage = (float(incorrect)/len(validation_data_labels))*100\n",
        "\n",
        "print(\"Correct: \", correct, \"(\", correct_percentage, \"%)\")\n",
        "print(\"Incorrect: \", incorrect, \"(\", incorrect_percentage, \"%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow2yFBylwUMt"
      },
      "source": [
        "# Testing Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEGW-jYJwrfi"
      },
      "source": [
        "predictions = clf.predict(test_data)\n",
        "\n",
        "while(True):\n",
        "  print()\n",
        "  print(\"There are\", len(test_data_labels), \"instances which can be tested.\")\n",
        "  print()\n",
        "\n",
        "  row = int(input(\"Enter a row number (0 exit): \"))\n",
        "\n",
        "  if(row == 0):\n",
        "    break\n",
        "  elif(row < 0 or row > len(test_data_labels)):\n",
        "    print(\"Error: Enter a number between 1 and\", len(test_data_labels))\n",
        "    continue\n",
        "  row = row-1\n",
        "  testLbl = labels[0] if (test_data_labels[row] == -1) else labels[1]\n",
        "  predLbl = labels[0] if (predictions[row] == -1) else labels[1]\n",
        "\n",
        "  print()\n",
        "  print(\"Predicted answer:\", predictions[row], predLbl)\n",
        "  print(\"Correct answer:\", test_data_labels[row], testLbl)\n",
        "  print()\n",
        "\n",
        "  state = \"Incorrect!\"\n",
        "  if (predictions[row] == test_data_labels[row]):\n",
        "    state = \"Correct!\"\n",
        "  print(\"Prediction is\", state)\n",
        "  print(\"***\")\n",
        "  print()\n",
        "\n",
        "print()\n",
        "print(\"Application terminated.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}